name: fashion-extraction
volumes:
  block-persist-project15:
services:
  extract-fashion-videos:
    container_name: fashion_extraction
    image: python:3.11
    user: root
    volumes:
      - block-persist-project15:/dev/vdb1/openvid
    working_dir: /app
    command:
      - bash
      - -c
      - |
        set -e
        echo "Creating script file..."
        cat > fashion_extraction_script.py << 'EOL'
        import os
        import subprocess
        import pandas as pd
        import requests
        import shutil
        import zipfile
        from concurrent.futures import ThreadPoolExecutor, as_completed
        from tqdm import tqdm

        # Set up directories
        OUTPUT_DIRECTORY = "/dev/vdb1/openvid"
        data_folder = os.path.join(OUTPUT_DIRECTORY, "data", "train")
        os.makedirs(data_folder, exist_ok=True)

        # Download OpenVid-1M.csv
        csv_url = "https://huggingface.co/datasets/nkp37/OpenVid-1M/resolve/main/data/train/OpenVid-1M.csv"
        csv_path = os.path.join(data_folder, "OpenVid-1M.csv")
        if not os.path.exists(csv_path):
            command = ["wget", "-O", csv_path, csv_url]
            try:
                subprocess.run(command, check=True)
                print(f"Downloaded {csv_url} to {csv_path}")
            except subprocess.CalledProcessError as e:
                print(f"Failed to download {csv_url}: {e}")

        # Load CSV
        df = pd.read_csv(csv_path)
        print("CSV loaded successfully")

        # Keywords for filtering
        # fashion_keywords = [
        #     'fashion show', 'runway', 'catwalk', 'fashion week', 'model walk', 'model runway',
        #     'couture show', 'collection launch', 'fashion presentation'
        # ]
        
        male_keywords = ['male model', 'man', 'menswear', 'male fashion']
        female_keywords = ['female model', 'woman', 'womenswear', 'female fashion']
        beauty_keywords = ['beautiful', 'gorgeous', 'stunning', 'elegant', 'chic', 'graceful', 'stylish']
        brand_keywords = ['adidas','nike']
        def is_relevant_fashion_show(caption):
            if not isinstance(caption, str):
                return False
            caption_lower = caption.lower()
            return (
                 #any(fk in caption_lower for fk in fashion_keywords) and
                any(mk in caption_lower for mk in male_keywords) and
                any(fek in caption_lower for fek in female_keywords) and
                # any(bk in caption_lower for bk in beauty_keywords) and
                any(bk in caption_lower for bk in brand_keywords)
        
        
            )

        # Apply filter
        filtered_df = df[df['caption'].apply(is_relevant_fashion_show)]

        # Select and rename relevant columns
        filtered_df = filtered_df[[
            'video', 'caption', 'aesthetic score', 'motion score',
            'temporal consistency score', 'seconds'
        ]].rename(columns={'seconds': 'duration_seconds'})

        # Sort by aesthetic score and motion score
        filtered_df = filtered_df.sort_values(by=['aesthetic score', 'motion score'], ascending=[False, False])

        print(f"Found {len(filtered_df)} relevant fashion show videos.")

        # Create a directory to store the CSV files
        os.makedirs("/dev/vdb1/openvid/OpenVid_CSVs", exist_ok=True)

        # Base URL for the CSV files
        base_url = "https://huggingface.co/datasets/phil329/OpenVid-1M-mapping/resolve/main/video_mappings/"

        # Download each CSV file
        for i in range(186):
          filename = f"OpenVid_part{i}.csv"
          url = base_url + filename
          csv_directory = os.path.join("/dev/vdb1/openvid/OpenVid_CSVs", filename)
          response = requests.get(url)
          if not os.path.exists(csv_directory):
            if response.status_code == 200:
                with open(csv_directory, "wb") as f:
                    f.write(response.content)
                print(f"Downloaded {filename}")
            else:
                print(f"Failed to download {filename}")
          else:
            print(f"Already exists {filename}")

        # Load all mapping files
        mappings = [pd.read_csv(f"/dev/vdb1/openvid/OpenVid_CSVs/OpenVid_part{i}.csv")
                   for i in range(186)]
        full_mapping = pd.concat(mappings)

        # Merge data
        merged_df = filtered_df.merge(full_mapping, on="video", how="left")
        print("Data merged successfully")

        # Find needed ZIPs
        needed_zips = merged_df["zip_file"].unique()
        print(f"Need to download {len(needed_zips)} zip files.")
        needed_paths = merged_df.groupby('zip_file')['video_path'].unique().to_dict()

        uuid_to_prompt = dict(zip(merged_df["video"], merged_df["caption"]))
        uuid_set = set(merged_df["video"])
        found = {}

        # Set up directories and error log
        error_log_path = os.path.join(OUTPUT_DIRECTORY, "download_log.txt")
        zip_folder = os.path.join('/dev/vdb1/openvid', "zip_files")
        temp_video_folder = os.path.join(OUTPUT_DIRECTORY, "only_fashion_show_dataset")
        os.makedirs(zip_folder, exist_ok=True)
        os.makedirs(temp_video_folder, exist_ok=True)

        # Function to download a zip file
        def download_with_progress(url, dest_path):
            try:
                response = requests.get(url, stream=True, timeout=30)
                if response.status_code != 200:
                    print(f"❌ Error: Invalid ZIP file URL {url} (Status code {response.status_code})")
                    with open(error_log_path, "a") as log:
                        log.write(f"Invalid URL: {url} (Status code {response.status_code})\n")
                    return False

                total_size = int(response.headers.get('content-length', 0))
                with open(dest_path, 'wb') as f:
                    downloaded = 0
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                            print(f"Downloading {dest_path}: {downloaded / total_size * 100:.2f}%", end="\r")
                return True
            except requests.RequestException as e:
                print(f"❌ Error downloading {url}: {e}")
                with open(error_log_path, "a") as log:
                    log.write(f"Download error for {url}: {e}\n")
                return False

        # Function to extract specific videos from the ZIP file
        def extract_video(zip_name):
            local_found = {}
            zip_file_path = os.path.join(zip_folder, zip_name)
            target_path = temp_video_folder

            try:
                with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
                    for path in needed_paths[zip_name]:
                        command = ['unzip', '-j', zip_file_path, path, '-d', target_path]

                        try:
                            subprocess.run(command, check=True)
                            print(f"✅ Extracted '{path}'")
                        except subprocess.CalledProcessError as e:
                            print(f"An error occurred: {e}")
                        final_idx = len(found) + 1
                        final_video_path = os.path.join(temp_video_folder, f"a ({final_idx}).mp4")
                        final_prompt_path = os.path.join(temp_video_folder, f"a ({final_idx}).txt")
                        if os.path.exists(final_video_path):
                            os.remove(final_video_path)
                        os.rename(os.path.join(target_path, os.path.basename(path)), final_video_path)
                        with open(final_prompt_path, "w", encoding="utf-8") as f:
                            f.write(uuid_to_prompt[os.path.basename(path)])

                        found[os.path.basename(path)] = True
                return local_found
            except subprocess.CalledProcessError as e:
                print(f"❌ Failed to extract from {zip_file_path}")
                return local_found

        # Function to download, extract videos, and save them
        def download_and_extract(zip_name):
            local_found = {}
            zip_file_path = os.path.join(zip_folder, zip_name)

            # Check if the zip file already exists
            if not os.path.exists(zip_file_path):
                url = f"https://huggingface.co/datasets/nkp37/OpenVid-1M/resolve/main/{zip_name}"
                print(f"Downloading {zip_file_path}...")

                if not download_with_progress(url, zip_file_path):
                    print(f"❌ Invalid ZIP file URL: {url}. Skipping download.")
                    return local_found
            else:
                print(f"✅ Already downloaded: {zip_file_path}")

            # Extract videos
            try:
                local_found = extract_video(zip_name)
                # Remove the zip file
                os.remove(zip_file_path)
                print(f"Deleted zip file: {zip_file_path}")
                return local_found
            except zipfile.BadZipFile as e:
                with open(error_log_path, "a") as log:
                    log.write(f"Bad ZIP file error ({zip_file_path}): {e}\n")
                print(f"❌ Failed to open ZIP file: {zip_file_path}")
                return local_found

        # Parallel execution
        with ThreadPoolExecutor(max_workers=3) as executor:
            future_to_zip = {executor.submit(download_and_extract, zip_name): zip_name for zip_name in needed_zips[0:1]}
            for future in tqdm(as_completed(future_to_zip), total=len(needed_zips), desc="Overall Progress"):
                result = future.result()

        print(f"🎉 Completed. Extracted {len(found)} matching videos.")
        EOL
        
        echo "Installing required packages..."
        pip install pandas requests tqdm
        
        echo "Creating directories..."
        mkdir -p /dev/vdb1/openvid/data/train
        mkdir -p /dev/vdb1/openvid/OpenVid_CSVs
        mkdir -p /dev/vdb1/openvid/zip_files
        mkdir -p /dev/vdb1/openvid/only_fashion_show_dataset
        
        echo "Running fashion extraction script..."
        python fashion_extraction_script.py
        
        echo "Extraction completed. Check /dev/vdb1/openvid for results."
